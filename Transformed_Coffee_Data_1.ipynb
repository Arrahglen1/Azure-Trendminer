{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import randn\n",
    "from pandas import Series, DataFrame\n",
    "from pylab import rcParams\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "###\n",
    "from pandas import read_csv\n",
    "from pandas import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\arrah\\Desktop\\Trendminer_Intern\\CoffeeML1.csv\", parse_dates =[\"timestamp\"])\n",
    "\n",
    "#df_large = read_csv(r\"C:\\Users\\arrah\\Desktop\\Trendminer_Intern\\CoffeeML1.csv\",index_col=0,squeeze=True,parse_dates =[\"timestamp\"])\n",
    "\n",
    "count_row = df.shape[0]  # gives number of row count\n",
    "count_column = df.shape[1] # gives number of column count\n",
    "\n",
    "print('Number of rows: {}'.format(count_row))\n",
    "print('Number of columns: {}'.format(count_column))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_0 = df1.drop(df1['2020-07-16 00:00:00':'2020-07-16 07:50:00'].index)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "startDate=['2020-07-16 05:00:00','2020-07-17 05:00:00','2020-07-18 05:00:00','2020-07-19 05:00:00','2020-07-20 05:00:00','2020-07-21 05:00:00','2020-07-22 05:00:00']\n",
    "endDate=['2020-07-16 17:00:00','2020-07-17 17:00:00','2020-07-18 17:00:00','2020-07-19 17:00:00','2020-07-20 17:00:00','2020-07-21 17:00:00','2020-07-22 17:00:00']\n",
    "#data_0[data_0.timestamp<endDate & startDate]\n",
    "#df[df['timestamp']>= startDate & df ['timestamp']<= endDate]\n",
    "result = []\n",
    "for i in  range(0, len(startDate)) :\n",
    "    start = startDate[i]\n",
    "    end = endDate[i]\n",
    "    result.append((df['timestamp'] > start) & (df['timestamp'] <= end)) \n",
    "\n",
    "resultDf = []\n",
    "for item in result:\n",
    "    if len(item)>0:\n",
    "        resultDf.append(df.loc[item])\n",
    "\n",
    "merged_df =pd.concat(resultDf)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= merged_df.set_index('timestamp')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2.resample('100ms',level=0).mean()\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df3.drop(['Keypad.keyPressed'], axis=1), df3['Keypad.keyPressed']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_inter = X.interpolate(method='linear', axis=0).ffill().bfill()\n",
    "X_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df1 = pd.concat([X_inter, y], axis=1)\n",
    "merged_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = merged_df1[['AnalogNoiseSensor.noiseTotal','Keypad.keyPressed']]\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3= df_2.reset_index()\n",
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10 =df_3[['AnalogNoiseSensor.noiseTotal']]\n",
    "df_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_len=300000\n",
    "global_k=60\n",
    "#global_start=200000\n",
    "# Applying only for the variable analognoise.total\n",
    "\n",
    "def generate_sample(k, sample_list):\n",
    "    result = []\n",
    "    for i in range(len(sample_list)):\n",
    "        if i < len(sample_list) - k:\n",
    "            result.append(sample_list[i : i+k])           \n",
    "    temp = np.array(result)\n",
    "    final_result = np.reshape(temp, (1, len(sample_list)-k, k))\n",
    "    return final_result\n",
    "    \n",
    "\n",
    "\n",
    "data_matrix = df_10[:global_len].values\n",
    "\n",
    "sampled_matrix_of_k = generate_sample(global_k, data_matrix)\n",
    "\n",
    "new_analog= pd.DataFrame(sampled_matrix_of_k[0])\n",
    "new_analog\n",
    "#sampled_matrix_of_k[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sliding_window_of_values(key_pad_frame, k):\n",
    "    keypad_matrix = key_pad_frame.values\n",
    "    \n",
    "    r = []\n",
    "    for i in range(len(keypad_matrix) - k):\n",
    "        print(keypad_matrix[i : i+k])\n",
    "        for y in range(len(keypad_matrix[i : i+k])):\n",
    "            if not math.isnan(keypad_matrix[i : i+k][y]):\n",
    "            \n",
    "                r.append(keypad_matrix[i : i+k][y])\n",
    "                break\n",
    "            elif y == len(keypad_matrix[i : i+k]) - 1:\n",
    "                r.append(keypad_matrix[i : i+k][y])\n",
    "        \n",
    "    return r\n",
    "                \n",
    "test_dataframe = df_3[\"Keypad.keyPressed\"][:global_len]\n",
    "\n",
    "keypadd = sliding_window_of_values(test_dataframe, global_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypadd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(keypadd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_timestamp =df_3[['timestamp']][:global_len-global_k]\n",
    "df_timestamp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # concantenating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_analog['keypad'] = keypadd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_analog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_frame = pd.concat([df_timestamp, new_analog], axis=1)\n",
    "merged_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of occurences greater than target_value in a list of integer\n",
    "def count_occurence_in_row(row, target_value):\n",
    "    count = 0\n",
    "    for i in range(len(row)):\n",
    "        if row[i] > target_value:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns true if the count in a row is greater or equal than the cutt_off_pt\n",
    "def is_valid_row(row, target_value, cut_off_pt):\n",
    "    if count_occurence_in_row(row, target_value) >= cut_off_pt:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_data_frame_with_valid_row(sample_data_frame, cutt_off_pt, target_value):\n",
    "    analog_df_values = sample_data_frame.drop(columns=['timestamp', 'keypad']).values\n",
    "    invalid_indexes = []\n",
    "    for index in range(len(analog_df_values)):\n",
    "        if not is_valid_row(analog_df_values[index], target_value, cutt_off_pt):\n",
    "            invalid_indexes.append(index)\n",
    "    return sample_data_frame.drop(sample_data_frame.index[invalid_indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exemple_frame = merged_frame[:100]\n",
    "exemple_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = exemple_frame.drop(columns=['timestamp', 'keypad']).values\n",
    "\n",
    "print(is_valid_row(mat[59], 15000, 40))\n",
    "\n",
    "print(count_occurence_in_row(row=mat[59], target_value=15000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_frame = create_data_frame_with_valid_row(merged_frame, cutt_off_pt=40, target_value=15000)\n",
    "\n",
    "result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#using the index as a list to do the filtering\n",
    "result_frame.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function uses the list and takes the first of consecutive sequence base on the difference we chose\n",
    "def drop_consecutive_row(input_df, delta ):\n",
    "    index_list = input_df.index.tolist()\n",
    "    index_to_keep = [index_list[0]]\n",
    "    for i in range(len(index_list)-1):\n",
    "        if index_list[i+1] - index_list[i] > delta:\n",
    "            index_to_keep.append(index_list[i+1])\n",
    "    return input_df.loc[index_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selecte_frame = drop_consecutive_row(result_frame, 50)\n",
    "selecte_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = selecte_frame.to_csv(r\"C:\\Users\\arrah\\Desktop\\Trendminer_Intern\\selecte_frame_15000_50_1.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_indep , Y_dep= selecte_frame.drop(['timestamp', 'keypad'], axis=1), selecte_frame['keypad']\n",
    "X_indep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = X1.to_csv(r\"C:\\Users\\arrah\\Desktop\\Trendminer_Intern\\x1__40.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final = pd.read_csv(r\"C:\\Users\\arrah\\Desktop\\Trendminer_Intern\\drop_consecutive_row_15000_40.csv\")\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final , Y_final= df_final.drop(['timestamp', 'keypad'], axis=1), df_final['keypad']\n",
    "X_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Models\n",
    "setting up for cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import scale\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(7,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "# Optionnal\n",
    "X_scale= pd.DataFrame(scaler.fit_transform(X_final), columns=X_final.columns)\n",
    "X_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and running your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clusters = 5\n",
    "kmeans = KMeans(n_clusters = clusters, random_state=123) \n",
    "y_assign=kmeans.fit(X_scale) \n",
    "\n",
    "print(y_assign.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(y_assign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=123)\n",
    "kmeans.fit(X_scale)\n",
    "y_kmeans = kmeans.predict(X_scale)\n",
    "y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_scale[:, 0], X_scale[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting your model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale.columns = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45','46','47','48','49','50','51','52','53','54','55','56','57','58','59']\n",
    "Y_dep.columns = ['keypad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting numpy to pandas\n",
    "dr = pd.DataFrame(data=y_assign.flatten())\n",
    "dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_theme = np.array(['darkgray', 'lightsalmon', 'powderblue'])\n",
    "\n",
    "# plt.subplot(1,2,1)\n",
    "\n",
    "# plt.scatter(x=iris_df.Petal_Length, y=iris_df.Petal_Width, c=color_theme[iris.target], s=50)\n",
    "# plt.title('Ground Truth Classification')\n",
    "\n",
    "# plt.subplot(1,2,2)\n",
    "\n",
    "# plt.scatter(x=iris_df.Petal_Length, y=iris_df.Petal_Width, c=color_theme[clustering.labels_], s=50)\n",
    "# plt.title('K-Means Classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate your clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relabel = np.choose(kmeans.labels_, [2, 0, 1, 3, 4]).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(classification_report(y_assign, relabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters = 5\n",
    "  \n",
    "# kmeans = KMeans(n_clusters = clusters) \n",
    "# y =kmeans.fit_predict(result_frame2) \n",
    "# y \n",
    "# #print(y.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting numpy to pandas\n",
    "# dr = pd.DataFrame(data=y.flatten())\n",
    "# dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = y.to_csv(r\"C:\\Users\\arrah\\Desktop\\Trendminer_Intern\\x1_15000_assign_40.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_frame2['cluster']= y\n",
    "result_frame2.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA   \n",
    "pca = PCA(3) \n",
    "pca.fit(result_frame2) \n",
    "  \n",
    "pca_data = pd.DataFrame(pca.transform(result_frame2)) \n",
    "  \n",
    "print(pca_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierachical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "%matplotlib inline \n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.cluster import AgglomerativeClustering \n",
    "from sklearn.preprocessing import StandardScaler, normalize \n",
    "from sklearn.metrics import silhouette_score \n",
    "import scipy.cluster.hierarchy as shc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sts = X1.iloc[:,:].values\n",
    "sts[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTERING Create Linkage Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(sts, 'ward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Dendrogram of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 10))\n",
    "plt.title('Hierachical Cluster Dendrogram ')\n",
    "plt.axhline(y=90000, color='r', linestyle='--')\n",
    "#plt.ylabel('distance')\n",
    "dendrogram(\n",
    "    Z,\n",
    "    labels = X1.index,\n",
    "    leaf_rotation = 0.,\n",
    "    leaf_font_size = 18.,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')  \n",
    "cluster.fit_predict(sts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(sts[:,0], sts[:,0], c=cluster.labels_, cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_frame1=result_frame[:50]\n",
    "result_frame1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_frame1.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_consecutive_row(input_df, delta ):\n",
    "    index_list = input_df.index.tolist()\n",
    "    index_to_keep = [index_list[0]]\n",
    "    for i in range(len(index_list)-1):\n",
    "        if index_list[i+1] - index_list[i] > delta:\n",
    "            index_to_keep.append(index_list[i+1])\n",
    "    return input_df.loc[index_to_keep]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_consecutive_row(result_frame1, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
